Data Representation and Manipulation

- Overview:
	- Binary represenation: Unsigned, signed (Two's complement), floating point
	representation (IEEE 754)
	- Hexadecimal representation and transformations

- Assume we have the bits 11000001 00001100 00000000 00000000
	- Unsigned value that can be written as 3238789120 in base 10
	- Signed (two's comp) that can be written as -105617876 in base 10
	- IEEE 754 floating point value that can be written as -8.75 
		- This is the standard representation of a float C 

- Recall that 1 byte is 8 bits, so one byte can hold values from 00000000 to 11111111
- This can be represented in Hexadecimal as 0x00 to 0xFF
- Hex uses the characters 0-9 and A-F to assign values from 0 to 15.
- Remember that each character in hex represents 4 bits, or half a byte. This means that
every two characters is one byte.

Word:
	- Machines have what we refer to as a "word size". Unlike bits, or bytes, which 
	will always have the same size, word-size on one machine is not necessarily the 
	same size as it may be on another machine.

	- The word size of a machine is the nominal size of integer-valued data. On 64-bit 
	machines, ints are typically 8 bytes (64 bits), thus the word size is 64 bits.
	On 32-bit machines, ints are typically 4 bytes (32 bits), thus the word size is 
	32 bits.

	- Note: integer size of the machine may or may not be the same size of an int on 
	specific programming languages. In C, when we declare an int, they are 4 bytes,
	even on most 64-bit machines.

	- Most current machines (64-bit) can address up to 1.8 * 10^19 bytes. Older machines
	(32-bit) limit address spaces to 4 GB - too small for memory intensive applications
	
	- Word-Oriented Memory Organization - Addresses specify Byte locations
	- Address of the first byte in a word, and successive words differ by 4 (32-bit machines)
	or 8 bytes (64-bit machines)


- Data representation in C:

	- Size of C data types:
	
	Data Type	Typical 64-bit	Typical 32-bit
	int		4		4
	long int	8		4
	char		1		1
	short		2		2
	float		4		4
	double		8		8
	char *		8		4


- Byte Ordering Conventions:
	- Big Endian: Place the least significant byte into the highest address
	- Little Endian: Place the least significant byte into the lowest address

	- Example: Assume we have a variable x such that x = 0x01234567.
	If we call on &x to get the address, we would receive 0x100, since this is 
	the lowest memory address that contains a value

	Memory address:	0x099	0x100	0x101	0x102	0x103	0x104	0x105
	Big Endian:		0x01	0x23	0x45	0x67		
	Little Endian:		0x67	0x45	0x23	0x01


- Bitwise Operators:
	- We have the following bitwise operators available:
		- & - and
		- | - or
		- ~ - not
		- ^ - xor

	- Assume we have the variables x=0x41 and y=0xBE. Note, each is 1 byte in size	
		- What is ~x?
		x = 0100 0001
	       ~x = 1011 1110
	       ~x = 0xBE
	- Assume we have the values x=0x65 and y=0x59
		- What is x & y
		x   = 0110 0101
		y   = 0101 1001
		x&y = 0100 0001
		    = 0x41
	- Assume we have the values x=0xB4, y=0x87
		- What is ~(x & y)
		x   = 1011 0100
		y   = 1000 0111
		x&y = 1000 0100
	      ~(x&y)= 0111 1011
		    = 0x7B

- Boolean Algebra:
	- Developed in 1800s (19th century)
	- Encode 1 as True, 0 as False
	- Primitive operations: AND, OR, and NOT
	- Primitive gates can be used for XOR
		- A^B = (~A & B) | (A & ~B)

	- Properties:
		- Commutative Sum: A^B = B^A
		- Commutative Product: A&B=B&A
		- Associative Sum: (A^B)^C = A^(B^C)
		- Associative Product: (A&B)&C = A&(B&C)
		- Product over sum (Distribution): A&(B^C) = (A^B)&(A^C)
		- 0 is sum identity: A^0 = A
		- 1 is product identity: A&1 = A
		- 0 is product annihilator: A&0 = 0
		- Additive Inverse: A ^ A = 0

- Logical Operations
	- Encode 1 as True, and 0 as False
	- &&: logical and
	- ||: logical or
	- ! : logical not
	- Examples: 
		- !0x41 = 0x00
		- 0x55 && 0x6B = 0x01
		- !(0x00 || 0x01) = 0x00

- Unsigned and Signed Ints:
	- X = x(w-1)x(w-2)...x(1)x(0)

- Unsigned = B2U(X) = (sum from i = 0 to w-1)(x(i)*2^i)
- Two's Complement: B2T(X) = -x(w-1)*2^(w-1)(sum from i = 0 to w-2)(x(i)*2^i)
	- 1 for negative in most significant bit
	- 0 for nonnegative

char x = 123: 01111011
char y = -123: 10000101

Weight		123		-123
     1           1		  1      +1
     2		 1                0
     4		 0                1      +4
     8		 1                0
     16          1		  0
     32          1		  0	
     64          1		  0
   -128	         0		  1     -128

					-123

- Converting from Unsigned to signed (two's complement):
	- Flip bits in postive number and add 1
	- 123:  01111011
	- flip: 10000100
	- add 1:10000101

- Numeric Ranges:
	- Unsigned numbers:
		- UMin = 0
		- Umax = (2^w) - 1
	- Signed ints (two's comp):
		- TMin = -(2^w-1)
		- TMax = (2^w-1)-1

- Values for w = 16
		Decimal		Hex		Binary
UMax		65535		FF FF		11111111 11111111
Tmax		32767		7F FF		01111111 11111111
Tmin           -32768		80 00		10000000 00000000
-1(2's comp)	-1		FF FF		11111111 11111111
0		0		00 00		00000000 00000000

- Word Sizes:
		8	16	32		64
Umax		255	65535	4294967295	~18 quintillion
Tmax		127	32767   2147483647	~9 quintillion
Tmin		-128	-32768 -2147483647	~-9 quintillion

- Observations:
	- |TMin| = TMax + 1
	- UMax = 2 * TMax +1

- C Programming:
	- #include <limits.h>
	- Declares the constants:
	- UCHAR_MAX (=255)
	- CHAR_MAX (127)
	- CHAR_MIN (-128)
	- INT_MIN
	- INT_MAX
	- UINT_MAX

- Sign extension ( Two's complement signed values)
	- Given a w-bit signed integer x, to convert it to a w+k bit integer of the same 
	value:
	- Make k copies of the sign bit
	- Ex:
		- X = 1001 (-7), w=4, k=4 (to reach 8 bits)
		- X' = 1111 1001 = (-7)

- 2's Complement and overflow 
	- Assume TAdd(u, v) adds the numbers u and v together
	- Determine if s = TAdd(u, v) overflows:
	- Overflow if and only if either:
		- u < 0, v < 0, s >= 0: Negative overflow
		- u >= 0, v > 0, s < 0: Positive overflow

- Shifting:
	- u << k : Shift u (usually a binary value) to the left k times
		- Get rid of bits on the left that are outside of our byte range
		- Fill in with 0's on the right

	- Example: w = 8, 1001 1100 << 3
			  128 + 16 + 8 + 4 = 156
			  1110 0000 
			  128 + 64 + 32 = 224
	- Example w = 16, 0000 0000 1001 1100 << 3
			  156 << 3
			  0000 0100 1110 0000 
			  1024 + 128 + 64 + 32 = 1248
	- 1248 / 156 = 8
	- Left shift multiplication: u << k = u * 2^k

	- Right shift: u >> k: shift u to the right k times
		- Get rid of values on the right
		- Logical Shift: fill in the left side with 0's
		- Arithmetic Shift: Replicate the most significant bit (the sign bit)
			on the left 
		- u >> k = u/2^k

-  IEEE 754 Floating Point Representation:

	- IEEE 754 Floating Point Representation is similar to the floating point representation
	from 132, when using the 132 method, it is possible to represent numbers in more 
	than one way. When using the normalization method from IEEE 754, you only have one 
	correct way to represent any given number. Implicit Normalization (IEEE 754) is more
	accurate than explicit normalization as well. 

	- Bias used in IEEE 754:
		- 16 bits: half-point precision: 
			- 11 bits for the significand (1 sign, the rest mantissa)
			- 5 bits for the exponent
			- Bias value: 15
		- 32 bits: single-point precision:
			- 24 bits for the significand 
			- 8 bits for the exponent
			- Bias: 127
		- 64 bits: double precision:
			- 53 bits for the significand
			- 11 bits for the exponent
			- Bias: 1023

	- Extra Notes: E = Exponent, m = mantissa, s = sign
		- E = 0000 0000, m = 00000..000, s = 0 or 1
			- This represents +0 or -0 
		- E = 1111 1111, m = 00000..000, s = 0
			- Positive infinity
		- E = 1111 1111, m = 00000..000, s = 1
			- Negative infinity
		- 1 <= E <= 254, m = xxxxx..xxx, s = 0 or 1
			- This is where we use the implicitly normalized form
			- We'll get to the conversion in a moment
		- S = 0 or 1, E = 0, M != 0:
			- This represents Fractional Form
			- Since this has no integer part it will have a different conversion
			than the implicitly normalized form
		- S = 0 or 1, E = 255, M != 0:
			- This is not a number (NAN)

	- Decoding Floating point numbers:
		- (-1)^S x 1.M x 2^(E-127)

	- For fractional form:
		- (-1)^S x 0.M x 2^(E-126)

	Examples:
	- Convert -4.25 to single point precision IEEE 754 floating point number
		- Step one: Convert to binary
			- 4 = 100
			- .25 = .01
			- 4.25 = 100.01
		- Step two: Use implicit normalization to shift the radix point to the 
			right of the most significant bit with a value of 1.
			This shift is done by multiplying your binary value by 2^k,
			where k is the number of positions you need to shift your radix 
			point.
			- 100.01 * 2^2 (k = 2)
			- 1.0001
			- The value to the right of the radix point is your mantissa
			- m = 0001
			- k is your "temporary exponent", since we still need to apply the 
			bias
		- Step 3: Bias your exponent by adding 127 to your temporary exponent.
			  This is your "True exponent". Convert this to Binary

			- 2 + 127 = 129

			- 129 = 1000 0001

		- Step 4: Fill in your sign, exponent and mantissa.

		S	Exponent	Mantissa
		1	1000 0001	00010000...00

	- Example: Convert 55.125 to IEEE 754 single-point precision floating point 
		representation.
		- 0 10000100 101110010000....00 x4
		Step 1: 55.125
			- 55 = 110111
			- .125 = 0.001
		Step 2: 110111.001 = 1.10111001 * 2^5

		Step 3: normalize exponent: 5 + 127 = 132 -> 10000100

		Step 4: fill in values:
		S	Exponent	Mantissa
		0	10000100	101110010000..000


	- Example 3: 1 10000011 1110001010000...000
		- -30.15625 x4

		Step 1: s = 1 (negative)
			m = 111000101
			E = 10000011
		Step 2: 128+1+2 = 131 - 127 = 4
		Step 3: 1.111000101 * 2^4 = 11110.00101 -> 30.15625
		Step 4: s = 1, so we get -30.15625

	Example 4: Fractional Form
		- convert 1 0000 0000 01100000...000 to decimal
		
		- (-1)^S x 0.M x 2^(-126)

		- (-1)^1 x 0.011 x 2^(-126)	

		- -1 * .375 x 2^(-126) = -.375 x 2^(-126) <- this form is OK


			
			
			 
